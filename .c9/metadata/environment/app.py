{"filter":false,"title":"app.py","tooltip":"/app.py","undoManager":{"mark":4,"position":4,"stack":[[{"start":{"row":0,"column":0},"end":{"row":46,"column":5},"action":"insert","lines":["import requests","import boto3","from datetime import datetime","import os","","def scrape_and_save(event, context):","    # URLs de las páginas a descargar","    urls = {","        'el_tiempo': 'https://www.eltiempo.com',","        'el_espectador': 'https://www.elespectador.com'","    }","    ","    # Configurar cliente de S3","    s3_client = boto3.client('s3')","    ","    # Nombre del bucket (debes crearlo previamente en AWS S3)","    bucket_name = 'tu-bucket-headlines'","    ","    # Obtener la fecha actual para la estructura del archivo","    today = datetime.utcnow().strftime('%Y-%m-%d')","    ","    # Descargar y guardar cada página","    for site, url in urls.items():","        try:","            # Descargar el contenido de la página","            response = requests.get(url)","            response.raise_for_status()  # Verificar si la solicitud fue exitosa","            content = response.text","            ","            # Definir la ruta en S3","            s3_key = f'headlines/raw/{site}-{today}.html'","            ","            # Subir el contenido a S3","            s3_client.put_object(","                Bucket=bucket_name,","                Key=s3_key,","                Body=content.encode('utf-8'),","                ContentType='text/html'","            )","            print(f\"Guardado {s3_key} en S3\")","        except Exception as e:","            print(f\"Error al procesar {site}: {str(e)}\")","    ","    return {","        'statusCode': 200,","        'body': 'Páginas descargadas y guardadas en S3'","    }"],"id":1}],[{"start":{"row":16,"column":19},"end":{"row":16,"column":38},"action":"remove","lines":["tu-bucket-headlines"],"id":2},{"start":{"row":16,"column":19},"end":{"row":16,"column":39},"action":"insert","lines":["arn:aws:s3:::tiempoe"]}],[{"start":{"row":0,"column":0},"end":{"row":46,"column":5},"action":"remove","lines":["import requests","import boto3","from datetime import datetime","import os","","def scrape_and_save(event, context):","    # URLs de las páginas a descargar","    urls = {","        'el_tiempo': 'https://www.eltiempo.com',","        'el_espectador': 'https://www.elespectador.com'","    }","    ","    # Configurar cliente de S3","    s3_client = boto3.client('s3')","    ","    # Nombre del bucket (debes crearlo previamente en AWS S3)","    bucket_name = 'arn:aws:s3:::tiempoe'","    ","    # Obtener la fecha actual para la estructura del archivo","    today = datetime.utcnow().strftime('%Y-%m-%d')","    ","    # Descargar y guardar cada página","    for site, url in urls.items():","        try:","            # Descargar el contenido de la página","            response = requests.get(url)","            response.raise_for_status()  # Verificar si la solicitud fue exitosa","            content = response.text","            ","            # Definir la ruta en S3","            s3_key = f'headlines/raw/{site}-{today}.html'","            ","            # Subir el contenido a S3","            s3_client.put_object(","                Bucket=bucket_name,","                Key=s3_key,","                Body=content.encode('utf-8'),","                ContentType='text/html'","            )","            print(f\"Guardado {s3_key} en S3\")","        except Exception as e:","            print(f\"Error al procesar {site}: {str(e)}\")","    ","    return {","        'statusCode': 200,","        'body': 'Páginas descargadas y guardadas en S3'","    }"],"id":3},{"start":{"row":0,"column":0},"end":{"row":27,"column":0},"action":"insert","lines":["import requests","from datetime import datetime","import boto3","","s3 = boto3.client('s3')","BUCKET = 'newste'","","def download_and_upload(url, source_name):","    response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})","    if response.status_code == 200:","        today = datetime.now().strftime(\"%Y-%m-%d\")","        filename = f\"headlines/raw/{source_name}-{today}.html\"","        s3.put_object(","            Bucket=BUCKET,","            Key=filename,","            Body=response.text.encode('utf-8'),","            ContentType='text/html'","        )","        return f\"{source_name} saved to {filename}\"","    else:","        return f\"Failed to fetch {source_name}: {response.status_code}\"","","def handler(event=None, context=None):","    logs = []","    logs.append(download_and_upload(\"https://www.eltiempo.com/\", \"eltiempo\"))","    logs.append(download_and_upload(\"https://www.elespectador.com/\", \"elespectador\"))","    return {\"result\": logs}",""]}],[{"start":{"row":27,"column":0},"end":{"row":27,"column":15},"action":"insert","lines":["zappa-94imvzxxt"],"id":4}],[{"start":{"row":27,"column":0},"end":{"row":27,"column":15},"action":"remove","lines":["zappa-94imvzxxt"],"id":5}]]},"ace":{"folds":[],"scrolltop":0,"scrollleft":0,"selection":{"start":{"row":0,"column":0},"end":{"row":26,"column":27},"isBackwards":true},"options":{"guessTabSize":true,"useWrapMode":false,"wrapToView":true},"firstLineState":0},"timestamp":1748998966574,"hash":"6a4c2c847ce9eb14397a8f128b2b1725e0bf9cef"}